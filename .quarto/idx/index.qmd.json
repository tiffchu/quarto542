{"title":"lab2_tchu2001","markdown":{"yaml":{"title":"lab2_tchu2001","listing":{"contents":"posts","sort":"date desc","type":"default","categories":true,"sort-ui":false,"filter-ui":false},"page-layout":"full","title-block-banner":true,"project":{"type":"website","output-dir":"docs"},"website":{"title":"Anomaly Detection of U.S. Congress Trades"},"format":{"html":{"theme":"cosmo","toc":true}}},"headingText":"Anomaly Detection of U.S. Congress Trades","containsRefs":false,"markdown":"\n\n\n\n\n*A tutorial and explanation using unsupervised machine learning*\n\nMembers of the United States Congress face long-standing concerns around\nconflicts of interest due to their access to market-moving information\nand their role in shaping economic policy. The [STOCK\nAct](https://www.congress.gov/bill/112th-congress/senate-bill/2038)\nrequires lawmakers to publicly disclose their financial transactions,\ncreating an opportunity for data-driven analysis of Congressional\ntrading behavior.\n\nHowever, transparency alone does not guarantee accountability. With\nhundreds of lawmakers and tens of thousands of disclosed trades,\nidentifying suspicious activity manually is impractical. This project\nexplores how **machine learning–based anomaly detection** can help flag\nunusual trading patterns that deserve closer scrutiny without making\naccusations or legal claims.\n\nUsing only public data, this tutorial demonstrates how unsupervised\nmodels can reduce a complex investigative problem into a manageable set\nof high-risk cases for journalists, researchers, and oversight bodies to\nexamine more closely.\n\n## Why Congressional Trading Is a Data Science Problem\n\nCongressional stock trading data is both large and structurally complex:\n\\* Hundreds of individual lawmakers \\* Thousands of trades across\ndifferent industries \\* Varying trade sizes, timing, and market\nconditions \\* Sparse labels - we rarely know which trades are illegal\n\nThis makes the problem ill-suited for traditional supervised machine\nlearning. We do not have ground-truth labels for “insider trading,” and\neven confirmed cases are extremely rare.\n\nYet the issue is far from hypothetical. Former Congressman [Chris\nCollins](https://www.justice.gov/usao-sdny/pr/former-congressman-christopher-collins-sentenced-insider-trading-scheme-and-lying)\nused non-public information about a pharmaceutical trial to sell shares\nand avoid over \\$700,000 in losses. A [New York Times\nanalysis](https://www.nytimes.com/interactive/2022/09/13/us/politics/congress-stock-trading-investigation.html)\nfound that roughly one-fifth of Congress members traded stocks related\nto industries overseen by their committees.\n\nThese examples highlight the need for scalable, computational analysis.\nMachine learning can help by identifying trades that look unusual\ncompared to typical behavior.\n\n## Project Goal\n\nThe goal of this project is not to accuse individuals of wrongdoing.\nInstead, it aims to **automatically identify trades that are\nstatistically unusual compared to typical Congressional trading\nbehavior**. You can follow along by using the code in this\n[repository.](https://github.com/tiffchu/Anomaly_Detection_US_Senate/blob/main/sprint4/capstone-sprint4-Main.ipynb)\n\nThese flagged trades can then be examined manually with additional\ncontext, such as committee memberships, news events, or regulatory\nactions. Machine learning narrows the search space, then humans provide\ninterpretation and judgment\n\n![Top earning congress members in 2024 through\ntrading](img/traders2.png)\n\n## Data Sources and Structure\n\nThis project uses only publicly available data, including:\n\n1.  Congressional trade disclosures\n\n-   Source: Senate stock transaction\n    [data](https://www.kaggle.com/datasets/shabbarank/congressional-trading-inception-to-march-23)\n-   Fields include transaction date, ticker, trade type, and trade value\n\n2.  Historical stock price data: S&P Data from Yfinance\n\n-   Used to calculate post-trade returns and market context\n\n3.  Contextual features, time series aggregates\n\n-   Time windows relative to trades\n-   Aggregated return statistics The resulting dataset contains\n    thousands of observations, each representing a single trade combined\n    with numerical features showing the current market.\n\n## Tutorial\n\n#### Data Cleaning and Preprocessing\n\nBefore applying machine learning, the raw data must be cleaned and\nstandardized.\n\nHandling Missing and Inconsistent Values Financial disclosure data from\nour dataset contains: \\* Ranges instead of exact trade values \\* Missing\nprices due to non-trading days \\* Inconsistent ticker formats These are\naddressed through: \\* Converting value ranges into numerical midpoints\n\\* Dropping trades with insufficient market data \\* Aligning trade dates\nwith nearest available trading days This step is critical as anomaly\ndetection is highly sensitive to noise.\n\n#### Feature Scaling\n\nBecause anomaly detection algorithms rely on distance metrics, feature\nscaling is essential. All numerical features are standardized so that\nlarge-scale features (e.g., returns) do not dominate smaller-scale ones\nThis ensures the model treats each signal proportionately.\n\n#### Feature Engineering\n\nRaw trades alone are not informative enough. The model needs features\nthat describe how unusual a trade is relative to normal behavior. Key\nengineered features include: \\* Post-trade returns over different time\nhorizons \\* Relative performance compared to the broader market \\* Trade\nfrequency patterns \\* Magnitude of price movement following the trade\nFor example, a trade followed by unusually high short-term returns may\nbe more suspicious than one aligned with normal market fluctuations.\nThese features transform qualitative concerns (“like the trade looking\nlucky or coincidental”) into quantitative signals.\n\n#### Unsupervised Anomaly Detection?\n\nUnlike fraud detection in credit cards, we do not have labeled examples\nof insider trading for Congress. So we inspect **which trades look most\ndifferent from the majority of Congressional trades?** Unsupervised\nanomaly detection models are ideal for this setting because they learn\nwhat “normal” looks like and flags deviations without prior labels. This\nproject explores two complementary approaches and combines results from\nboth.\n\n#### Method 1: Agglomerative Clustering\n\nAgglomerative clustering is a hierarchical method that groups similar\ndata points together. The intuition behind this is that most trades\nbehave similarly and cluster together and anomalous trades form small,\ndistant clusters. The algorithm starts with each trade as its own\ncluster and iteratively merges the closest clusters until a predefined\nstructure is reached. Trades belonging to very small or isolated\nclusters are treated as potential anomalies. **Pros:** Simple and\ninterpretable, effective for identifying extreme outliers, and no\nassumptions about data distribution. This method serves as a baseline\nanomaly detector and provides intuition about the structure of the data.\n\n![After dimensionality reduction of the dataset and using the clustering\nmodel resulting labels to define cluster\ncolors](img/pca_a.png){#fig-pca_a}\n\n![dendrogram cluster visualization longer vertical lines connecting\npoints = larger distances (the second\ncluster)](img/dendro.png){#fig-dendro}\n\n### Method 2: Autoencoder Neural Network\n\nTo capture more subtle patterns, the project also uses an autoencoder, a\ntype of neural network designed for unsupervised learning. An\nautoencoder learns to: Compress the input data into a low-dimensional\nrepresentation Reconstruct the original data from that representation\nDuring training, it learns the dominant patterns present in the dataset.\n*Anomaly detection via reconstruction error*: Normal trades are\nreconstructed accurately and unusual trades have high reconstruction\nerror This error becomes the anomaly score. *Pros:* anomalies are subtle\nrather than extreme and relationships between features are non-linear\n\n![Principal Component Analysis (PCA) on a dataset to reduce\ndimensionality to two component and then displays the transformed data\nin a scatter plot colored by cluster\nlabels](img/pca_ae.png){#fig-pca_ae}\n\n![Anomaly-Detected Congress members and the top investors in that\ngroup](img/bar.png){#fig-bar}\n\n### Comparing the Two Methods\n\n| Method                   | Strengths                 | Limitations             |\n|------------------------|-------------------------|------------------------|\n| Agglomerative Clustering | Simple, interpretable     | Misses subtle anomalies |\n| Autoencoder              | Captures complex patterns | Less transparent        |\n\nUsing both methods provides robustness: trades flagged by multiple\nmodels deserve particular attention.\n\n#### Visualizing Anomalies\n\nVisualization plays a crucial role in interpretation. Above, we used: \\*\nDimensionality reduction plots (PCA) showing separation between normal\nand flagged trades \\* Ranked bar charts of the most suspicious trades\nand lawmakers These visuals help answer: How extreme are flagged trades\ncompared to the norm? Are anomalies isolated or systematic?\n\n### Interpreting the Results\n\nThe models consistently flag trades that: \\* Exhibit unusually high\nshort-term returns \\* Occur at statistically rare times relative to\nmarket movements \\* Appear inconsistent with typical Congressional\ntrading behavior Importantly, being flagged does not imply guilt.\nInnocent behavior can trigger anomalies, especially during volatile\nmarkets. However, the key advantage is scale reduction, from thousands\nof trades to a small subset worthy of deeper investigation\n\n![plot](img/repub.png){#fig-rep} ![plot](img/democrat.png){#fig-demo}\n","srcMarkdownNoYaml":"\n\n\n\n# Anomaly Detection of U.S. Congress Trades\n\n*A tutorial and explanation using unsupervised machine learning*\n\nMembers of the United States Congress face long-standing concerns around\nconflicts of interest due to their access to market-moving information\nand their role in shaping economic policy. The [STOCK\nAct](https://www.congress.gov/bill/112th-congress/senate-bill/2038)\nrequires lawmakers to publicly disclose their financial transactions,\ncreating an opportunity for data-driven analysis of Congressional\ntrading behavior.\n\nHowever, transparency alone does not guarantee accountability. With\nhundreds of lawmakers and tens of thousands of disclosed trades,\nidentifying suspicious activity manually is impractical. This project\nexplores how **machine learning–based anomaly detection** can help flag\nunusual trading patterns that deserve closer scrutiny without making\naccusations or legal claims.\n\nUsing only public data, this tutorial demonstrates how unsupervised\nmodels can reduce a complex investigative problem into a manageable set\nof high-risk cases for journalists, researchers, and oversight bodies to\nexamine more closely.\n\n## Why Congressional Trading Is a Data Science Problem\n\nCongressional stock trading data is both large and structurally complex:\n\\* Hundreds of individual lawmakers \\* Thousands of trades across\ndifferent industries \\* Varying trade sizes, timing, and market\nconditions \\* Sparse labels - we rarely know which trades are illegal\n\nThis makes the problem ill-suited for traditional supervised machine\nlearning. We do not have ground-truth labels for “insider trading,” and\neven confirmed cases are extremely rare.\n\nYet the issue is far from hypothetical. Former Congressman [Chris\nCollins](https://www.justice.gov/usao-sdny/pr/former-congressman-christopher-collins-sentenced-insider-trading-scheme-and-lying)\nused non-public information about a pharmaceutical trial to sell shares\nand avoid over \\$700,000 in losses. A [New York Times\nanalysis](https://www.nytimes.com/interactive/2022/09/13/us/politics/congress-stock-trading-investigation.html)\nfound that roughly one-fifth of Congress members traded stocks related\nto industries overseen by their committees.\n\nThese examples highlight the need for scalable, computational analysis.\nMachine learning can help by identifying trades that look unusual\ncompared to typical behavior.\n\n## Project Goal\n\nThe goal of this project is not to accuse individuals of wrongdoing.\nInstead, it aims to **automatically identify trades that are\nstatistically unusual compared to typical Congressional trading\nbehavior**. You can follow along by using the code in this\n[repository.](https://github.com/tiffchu/Anomaly_Detection_US_Senate/blob/main/sprint4/capstone-sprint4-Main.ipynb)\n\nThese flagged trades can then be examined manually with additional\ncontext, such as committee memberships, news events, or regulatory\nactions. Machine learning narrows the search space, then humans provide\ninterpretation and judgment\n\n![Top earning congress members in 2024 through\ntrading](img/traders2.png)\n\n## Data Sources and Structure\n\nThis project uses only publicly available data, including:\n\n1.  Congressional trade disclosures\n\n-   Source: Senate stock transaction\n    [data](https://www.kaggle.com/datasets/shabbarank/congressional-trading-inception-to-march-23)\n-   Fields include transaction date, ticker, trade type, and trade value\n\n2.  Historical stock price data: S&P Data from Yfinance\n\n-   Used to calculate post-trade returns and market context\n\n3.  Contextual features, time series aggregates\n\n-   Time windows relative to trades\n-   Aggregated return statistics The resulting dataset contains\n    thousands of observations, each representing a single trade combined\n    with numerical features showing the current market.\n\n## Tutorial\n\n#### Data Cleaning and Preprocessing\n\nBefore applying machine learning, the raw data must be cleaned and\nstandardized.\n\nHandling Missing and Inconsistent Values Financial disclosure data from\nour dataset contains: \\* Ranges instead of exact trade values \\* Missing\nprices due to non-trading days \\* Inconsistent ticker formats These are\naddressed through: \\* Converting value ranges into numerical midpoints\n\\* Dropping trades with insufficient market data \\* Aligning trade dates\nwith nearest available trading days This step is critical as anomaly\ndetection is highly sensitive to noise.\n\n#### Feature Scaling\n\nBecause anomaly detection algorithms rely on distance metrics, feature\nscaling is essential. All numerical features are standardized so that\nlarge-scale features (e.g., returns) do not dominate smaller-scale ones\nThis ensures the model treats each signal proportionately.\n\n#### Feature Engineering\n\nRaw trades alone are not informative enough. The model needs features\nthat describe how unusual a trade is relative to normal behavior. Key\nengineered features include: \\* Post-trade returns over different time\nhorizons \\* Relative performance compared to the broader market \\* Trade\nfrequency patterns \\* Magnitude of price movement following the trade\nFor example, a trade followed by unusually high short-term returns may\nbe more suspicious than one aligned with normal market fluctuations.\nThese features transform qualitative concerns (“like the trade looking\nlucky or coincidental”) into quantitative signals.\n\n#### Unsupervised Anomaly Detection?\n\nUnlike fraud detection in credit cards, we do not have labeled examples\nof insider trading for Congress. So we inspect **which trades look most\ndifferent from the majority of Congressional trades?** Unsupervised\nanomaly detection models are ideal for this setting because they learn\nwhat “normal” looks like and flags deviations without prior labels. This\nproject explores two complementary approaches and combines results from\nboth.\n\n#### Method 1: Agglomerative Clustering\n\nAgglomerative clustering is a hierarchical method that groups similar\ndata points together. The intuition behind this is that most trades\nbehave similarly and cluster together and anomalous trades form small,\ndistant clusters. The algorithm starts with each trade as its own\ncluster and iteratively merges the closest clusters until a predefined\nstructure is reached. Trades belonging to very small or isolated\nclusters are treated as potential anomalies. **Pros:** Simple and\ninterpretable, effective for identifying extreme outliers, and no\nassumptions about data distribution. This method serves as a baseline\nanomaly detector and provides intuition about the structure of the data.\n\n![After dimensionality reduction of the dataset and using the clustering\nmodel resulting labels to define cluster\ncolors](img/pca_a.png){#fig-pca_a}\n\n![dendrogram cluster visualization longer vertical lines connecting\npoints = larger distances (the second\ncluster)](img/dendro.png){#fig-dendro}\n\n### Method 2: Autoencoder Neural Network\n\nTo capture more subtle patterns, the project also uses an autoencoder, a\ntype of neural network designed for unsupervised learning. An\nautoencoder learns to: Compress the input data into a low-dimensional\nrepresentation Reconstruct the original data from that representation\nDuring training, it learns the dominant patterns present in the dataset.\n*Anomaly detection via reconstruction error*: Normal trades are\nreconstructed accurately and unusual trades have high reconstruction\nerror This error becomes the anomaly score. *Pros:* anomalies are subtle\nrather than extreme and relationships between features are non-linear\n\n![Principal Component Analysis (PCA) on a dataset to reduce\ndimensionality to two component and then displays the transformed data\nin a scatter plot colored by cluster\nlabels](img/pca_ae.png){#fig-pca_ae}\n\n![Anomaly-Detected Congress members and the top investors in that\ngroup](img/bar.png){#fig-bar}\n\n### Comparing the Two Methods\n\n| Method                   | Strengths                 | Limitations             |\n|------------------------|-------------------------|------------------------|\n| Agglomerative Clustering | Simple, interpretable     | Misses subtle anomalies |\n| Autoencoder              | Captures complex patterns | Less transparent        |\n\nUsing both methods provides robustness: trades flagged by multiple\nmodels deserve particular attention.\n\n#### Visualizing Anomalies\n\nVisualization plays a crucial role in interpretation. Above, we used: \\*\nDimensionality reduction plots (PCA) showing separation between normal\nand flagged trades \\* Ranked bar charts of the most suspicious trades\nand lawmakers These visuals help answer: How extreme are flagged trades\ncompared to the norm? Are anomalies isolated or systematic?\n\n### Interpreting the Results\n\nThe models consistently flag trades that: \\* Exhibit unusually high\nshort-term returns \\* Occur at statistically rare times relative to\nmarket movements \\* Appear inconsistent with typical Congressional\ntrading behavior Importantly, being flagged does not imply guilt.\nInnocent behavior can trigger anomalies, especially during volatile\nmarkets. However, the key advantage is scale reduction, from thousands\nof trades to a small subset worthy of deeper investigation\n\n![plot](img/repub.png){#fig-rep} ![plot](img/democrat.png){#fig-demo}\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.7.33","theme":["cosmo","brand"],"title":"lab2_tchu2001","listing":{"contents":"posts","sort":"date desc","type":"default","categories":true,"sort-ui":false,"filter-ui":false},"page-layout":"full","title-block-banner":true},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}